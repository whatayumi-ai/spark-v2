import os
import json
import numpy as np
import google.generativeai as genai
from typing import List, Optional
from sklearn.metrics.pairwise import cosine_similarity
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs
from models import SmartBlock
import prompts

# é…ç½® API KEY
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

class SparkEngine:
    def __init__(self):
        self.database: List[SmartBlock] = []
        # ä½¿ç”¨ä½ åˆšæ‰éªŒè¯é€šè¿‡çš„æœ€å¼ºæ¨¡å‹
        self.model = genai.GenerativeModel('gemini-2.0-flash')

    def _extract_video_id(self, url):
        """ä» YouTube URL ä¸­æå– Video ID"""
        query = urlparse(url)
        if query.hostname == 'youtu.be':
            return query.path[1:]
        if query.hostname in ('www.youtube.com', 'youtube.com'):
            if query.path == '/watch':
                p = parse_qs(query.query)
                return p['v'][0]
            if query.path[:7] == '/embed/':
                return query.path.split('/')[2]
            if query.path[:3] == '/v/':
                return query.path.split('/')[2]
        return None

    def _fetch_transcript(self, url, start_min=None, end_min=None):
        """æŠ“å–å­—å¹•å¹¶æ ¹æ®æ—¶é—´è¿‡æ»¤"""
        try:
            video_id = self._extract_video_id(url)
            if not video_id:
                return "Error: æ— æ•ˆçš„ YouTube é“¾æ¥"
            
            # è·å–å­—å¹•åˆ—è¡¨ (è‡ªåŠ¨å°è¯•ä¸­æ–‡å’Œè‹±æ–‡)
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['zh-Hans', 'zh-Hant', 'en'])
            
            full_text = []
            for item in transcript_list:
                start_time = item['start']
                text = item['text']
                
                # å¦‚æœæŒ‡å®šäº†æ—¶é—´èŒƒå›´ (ç²¾ç ”æ¨¡å¼)
                if start_min is not None and end_min is not None:
                    if start_time < start_min * 60: continue
                    if start_time > end_min * 60: break
                
                full_text.append(text)
            
            return " ".join(full_text)
        except Exception as e:
            return f"å­—å¹•æŠ“å–å¤±è´¥ (å¯èƒ½è¯¥è§†é¢‘æ²¡æœ‰CCå­—å¹•): {str(e)}"

    def _call_llm(self, prompt):
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"Error processing AI: {e}"

    def _get_embedding(self, text):
        try:
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=text,
                task_type="retrieval_document", 
                title="Spark Block" 
            )
            return result['embedding']
        except Exception as e:
            print(f"Embedding Error: {e}")
            return []

    def process_block(self, block: SmartBlock):
        print(f"ğŸ”„ [Gemini] æ­£åœ¨å¤„ç†: {block.source_type} ...")
        
        # --- æ ¸å¿ƒæ”¹åŠ¨ï¼šå¦‚æœæ˜¯è§†é¢‘ï¼Œå…ˆæŠ“å–å†…å®¹ ---
        content_to_process = block.raw_content
        
        if block.source_type == "video_snippet":
            # æ£€æŸ¥ metadata é‡Œæœ‰æ²¡æœ‰ URL
            url = block.metadata.get('url')
            if url:
                print(f"ğŸ“º æ­£åœ¨æŠ“å– YouTube å­—å¹•: {url}")
                # è·å–æ—¶é—´èŒƒå›´è®¾ç½®
                s_min = block.metadata.get('start_min')
                e_min = block.metadata.get('end_min')
                
                # æŠ“å–å­—å¹•è¦†ç›–æ‰åŸå§‹çš„ raw_content
                fetched_text = self._fetch_transcript(url, s_min, e_min)
                if "Error" in fetched_text or "å¤±è´¥" in fetched_text:
                    block.processed_content = f"âŒ {fetched_text}"
                    return # ç»ˆæ­¢å¤„ç†
                
                content_to_process = fetched_text
                # æŠŠæŠ“åˆ°çš„æ–‡å­—å­˜å›å»ï¼Œæ–¹ä¾¿æŸ¥çœ‹
                block.raw_content = f"[å·²æå–å­—å¹•] {url}\n\n{fetched_text[:200]}..."

        # 1. æ–‡æœ¬æ•´å½¢
        if block.source_type == "video_snippet":
            final_prompt = prompts.VIDEO_PROCESS_PROMPT.format(text=content_to_process)
        elif block.source_type == "chat_log":
            final_prompt = prompts.CHAT_PROCESS_PROMPT.format(text=content_to_process)
        else:
            final_prompt = content_to_process
            
        block.processed_content = self._call_llm(final_prompt)
        
        # 2. è‡ªåŠ¨æ‰“æ ‡
        tag_prompt = prompts.TAGGING_PROMPT.format(content=block.processed_content)
        tags_raw = self._call_llm(tag_prompt)
        try:
            clean_json = tags_raw.replace("```json", "").replace("```", "").strip()
            block.ai_tags = json.loads(clean_json)
        except:
            block.ai_tags = ["#AI_Tag_Error"]

        # 3. å‘é‡åŒ–
        if block.processed_content:
            block.embedding = self._get_embedding(block.processed_content)
            
        self.database.append(block)
        print(f"âœ… å¤„ç†å®Œæˆ: ID {block.id[:6]}")

    def find_related(self, target_block: SmartBlock, top_k=3):
        # ... (è¿™éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜) ...
        if not target_block.embedding or not self.database:
            return []
        db_embeddings = [b.embedding for b in self.database if b.id != target_block.id and b.embedding]
        db_blocks = [b for b in self.database if b.id != target_block.id and b.embedding]
        if not db_embeddings: return []
        target_vec = np.array(target_block.embedding).reshape(1, -1)
        db_matrix = np.array(db_embeddings)
        similarities = cosine_similarity(target_vec, db_matrix)[0]
        top_indices = similarities.argsort()[-top_k:][::-1]
        results = []
        for idx in top_indices:
            score = similarities[idx]
            if score > 0.3: results.append((db_blocks[idx], score))
        return results