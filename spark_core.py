import os
import json
import time
import google.generativeai as genai
from typing import List
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from models import SmartBlock
import prompts

# --- åº“å¯¼å…¥: åªä¿ç•™å­—å¹•åº“ï¼Œç§»é™¤ yt_dlp ---
try:
    from youtube_transcript_api import YouTubeTranscriptApi
except ImportError:
    YouTubeTranscriptApi = None

# é…ç½® API KEY
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

class SparkEngine:
    def __init__(self):
        self.database: List[SmartBlock] = []
        # ä¿ç•™ä¿®å¤: ä½¿ç”¨æœ€æ–°çš„ 2.5 ç‰ˆæœ¬
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    def _call_llm(self, prompt):
        """è°ƒç”¨å¤§æ¨¡å‹"""
        # ä¿ç•™ä¿®å¤: å¼ºåˆ¶ä¼‘æ¯ 2 ç§’ï¼Œé˜²æ­¢ 429 æŠ¥é”™
        print("â³ æ­£åœ¨ç­‰å¾… API å†·å´ (2s)...")
        time.sleep(2) 
        
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"Error processing AI: {e}"

    def _get_youtube_transcript(self, url):
        """åªæŠ“å–å­—å¹•"""
        if not YouTubeTranscriptApi:
            return None, "âŒ æœªå®‰è£… transcript åº“"
            
        try:
            video_id = None
            if "v=" in url:
                video_id = url.split("v=")[1].split("&")[0]
            elif "youtu.be/" in url:
                video_id = url.split("youtu.be/")[1].split("?")[0]
            
            if not video_id:
                return None, "æ— æ³•è§£æ Video ID"

            # å°è¯•æŠ“å–å¤šè¯­è¨€å­—å¹•
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['zh-CN', 'zh-Hans', 'zh-Hant', 'en'])
            full_text = " ".join([t['text'] for t in transcript_list])
            return f"[è‡ªåŠ¨æŠ“å–çš„å­—å¹•] {full_text}", None
            
        except Exception as e:
            return None, str(e)

    def _get_embedding(self, text):
        try:
            time.sleep(1)
            truncated_text = text[:9000]
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=truncated_text,
                task_type="retrieval_document", 
                title="Spark Block" 
            )
            return result['embedding']
        except Exception as e:
            return []

    def process_block(self, block: SmartBlock, file_bytes=None):
        print(f"ğŸ”„ [Gemini] æ­£åœ¨å¤„ç†: {block.source_type} ...")
        
        prompt_text = block.raw_content
        status_msg = ""

        # === æ ¸å¿ƒé€»è¾‘: åªå¤„ç†å­—å¹• ===
        if block.source_type == "video_snippet" and ("youtube.com" in block.raw_content or "youtu.be" in block.raw_content):
            transcript_text, error = self._get_youtube_transcript(block.raw_content)
            
            if transcript_text:
                print("âœ… æˆåŠŸæŠ“å–å­—å¹•")
                prompt_text = transcript_text
                status_msg = "(åŸºäºCCå­—å¹•)"
            else:
                # å¦‚æœæ²¡æœ‰å­—å¹•ï¼Œç›´æ¥æŠ¥é”™ï¼Œä¸å†å°è¯•ä¸‹è½½éŸ³é¢‘
                print(f"âŒ å­—å¹•è·å–å¤±è´¥: {error}")
                block.processed_content = f"âŒ æ­¤è§†é¢‘æ²¡æœ‰CCå­—å¹•ï¼Œä¸”éŸ³é¢‘ä¸‹è½½åŠŸèƒ½å·²å…³é—­ã€‚\né”™è¯¯ä¿¡æ¯: {error}"
                return

        # === å‡†å¤‡ Prompt ===
        if block.source_type == "video_snippet":
            # ç®€åŒ– Promptï¼Œä¸å†éœ€è¦å¤„ç†éŸ³é¢‘çš„é€»è¾‘
            final_prompt = prompts.VIDEO_PROCESS_PROMPT.format(text=prompt_text)
        elif block.source_type == "chat_log":
            final_prompt = prompts.CHAT_PROCESS_PROMPT.format(text=prompt_text)
        else:
            final_prompt = prompt_text
        
        # --- ä¿ç•™ä¿®å¤: åˆå¹¶ Prompt (æ€»ç»“+æ ‡ç­¾ ä¸€æ¬¡æå®š) ---
        combined_prompt = final_prompt + "\n\n" + "-"*20 + "\nã€é™„åŠ ä»»åŠ¡ã€‘åœ¨ç¬”è®°çš„æœ€åï¼Œè¯·åŠ¡å¿…å¦èµ·ä¸€è¡Œï¼Œä»¥ JSON æ ¼å¼è¾“å‡º 3-5 ä¸ªæ ¸å¿ƒæ ‡ç­¾ï¼Œæ ¼å¼ä¸¥æ ¼å¦‚ä¸‹ï¼š\nTagsJSON: [\"#æ ‡ç­¾1\", \"#æ ‡ç­¾2\", \"#æ ‡ç­¾3\"]"

        # 1. è°ƒç”¨ LLM
        full_response = self._call_llm(combined_prompt)
        
        # 2. è§£æç»“æœ
        if full_response and "TagsJSON:" in full_response:
            try:
                parts = full_response.split("TagsJSON:")
                content_part = parts[0].strip()
                tags_json_str = parts[1].strip().replace("```json", "").replace("```", "").strip()
                
                block.processed_content = f"{status_msg}\n\n{content_part}"
                block.ai_tags = json.loads(tags_json_str)
            except:
                block.processed_content = f"{status_msg}\n\n{full_response}"
                block.ai_tags = ["#TagParseError"]
        else:
            block.processed_content = f"{status_msg}\n\n{full_response}"
            block.ai_tags = []

        # 3. Embedding
        if block.processed_content and "Error" not in block.processed_content:
            block.embedding = self._get_embedding(block.processed_content)
            self.database.append(block)
            print(f"âœ… å¤„ç†å®Œæˆ: ID {block.id[:6]}")

    def find_related(self, target_block: SmartBlock, top_k=3):
        # ... (è¿™éƒ¨åˆ†ä¿æŒä¸å˜) ...
        if not target_block.embedding or not self.database:
            return []
        db_embeddings = [b.embedding for b in self.database if b.id != target_block.id and b.embedding]
        db_blocks = [b for b in self.database if b.id != target_block.id and b.embedding]
        if not db_embeddings:
            return []
        target_vec = np.array(target_block.embedding).reshape(1, -1)
        db_matrix = np.array(db_embeddings)
        similarities = cosine_similarity(target_vec, db_matrix)[0]
        top_indices = similarities.argsort()[-top_k:][::-1]
        results = []
        for idx in top_indices:
            score = similarities[idx]
            if score > 0.3:
                results.append((db_blocks[idx], score))
        return results